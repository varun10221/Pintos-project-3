      +--------------------+
      |        CS 140      |
      | PROJECT 1: THREADS |
      |   DESIGN DOCUMENT  |
      +--------------------+
           
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Jamie Davis <davisjam@vt.edu>
Mai Dahshan <mdahshan@vt.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

           ALARM CLOCK
           ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

timer_sleep() appends the running thread to the sleeping_list.
This update to the sleeping_list is kept atomic through the use of a lock.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

The situation here is that a thread is running timer_sleep and a timer
interrupt occurs. 

CASE: The timer interrupt handler traverses and potentially removes elements from the sleeping_list.
It does not hold a lock. I don't see a good way around this race condition besides disabling interrupts
in timer_sleep while we modify sleeping_list.

CASE: The timer interrupt handler just Ups a semaphore. This (eventually) wakes waker_thread, who
waits for the lock on the sleeping_list before modifying it. No race condition since we revert to
well-defined lock semantics.

HOWEVER: if the timer interrupt handler interrupts a call to timer_sleep while we are computing
when to wake us up, and it uses X ticks, then we potentially sleep X + ticks_to_sleep ticks.
If X >> ticks_to_sleep, this could be bad.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

For Monday 31 Aug:
Jamie's proposed design

  As provided, timer_sleep calls thread_yield until ticks <= timer_elapsed.
  thread_yield puts the caller at the end of the ready list, leaves its state as THREAD_READY, and then schedules a thread to run
    (could be the caller). This can result in busy looping, using up CPU cycles scheduling and unscheduling the sleeping thread
    until enough ticks have passed. For short sleeps this is OK, but for long sleeps this wastes a lot of CPU.

  It would be preferable if the sleeping thread were not considered for scheduling until its requested number of ticks have passed.
  There is no requirement that the thread be woken up after exactly x ticks (unless the system is otherwise idle).

  Proposal 1: Complete accuracy, at the expense (perhaps) of system responsiveness
  
  - Introduce a new list of sleeping threads in thread.c: static struct list sleeping_list
  - Add a wake_me_at field to struct thread, used to track the minimum value of ticks in 'ticks' before which we can be woken (this could also be done with a struct tracking a thread and a wake_me_at field, but this seems like a needless use of memory)
  - When a thread calls timer_sleep, it adds itself to this list and yields
  - In the timer interrupt handler, traverse the sleeping_list and add to ready_list any threads list that have finished their sleep

  Problem: If the system has a lot of threads that call timer_sleep, traversing the sleeping_list to find threads that should be woken can be expensive.
    The interrupt handler must run as fast as possible to improve system responsiveness. We don't want to spend ticks iterating over a list.

  Variation: keep the sleeping_list sorted by soonest-to-wake, minimizing the time spent traversing it in the timer interrupt handler. This makes insertion more expensive, which in turn makes the timer interrupt handler take longer.
    
  Proposal 2: System responsiveness, at the expense of timer accuracy

  (The first three are the same as Proposal 1)
  - Introduce a new list of sleeping threads in thread.c: static struct list sleeping_list
  - Add a wake_me_at field to struct thread, used to track the minimum value of ticks in 'ticks' before which we can be woken
  Differences:
  - Introduce another "system" thread (joining the elite club of idle_thread and initial_thread). Call it waker_thread.
     waker_thread is always on the ready list and when scheduled, it:
      - iterates over the sleeping_list
      - adds any ready-to-wake threads to the ready_list
      - yields

  Here we're still burning CPU cycles busy-waiting, but in a high-sleeper-count scenario only *one* thread (the waker_thread) is being scheduled to burn cycles instead of multiple threads. In a low-sleeper-count scenario this is roughly the same as what we have now anyway.

  Variation 1: Instead of introducing a waker_thread, have the idle_thread check the sleeper_list instead. It's not doing anything else anyway. However, this could starve sleepers. The idle_thread only runs when the ready_list is empty, so if there are always ready threads, idle would never run and thus sleepers would never be woken. Failure!

  Variation 2: Have waker_thread wait on a semaphore (monitor?) and have the timer interrupt "Up" the semaphore. This does not require busy waiting. waker_thread is therefore only ever scheduled to run by the timer interrupt, instead of at the same rate as every other thread in the ready list.

  Variation 3: Just stick sleeping threads in the ready_list, mark them as SLEEPING, and don't schedule them until enough time has passed. This has minimal complexity but makes the scheduling activity pricey! I think the list traversal could become unpleasantly expensive.

  Files to modify:
    - thread.h: thread_status
    - thread.h: struct thread

Mai's proposed design
  TODO

       PRIORITY SCHEDULING
       ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

For Monday 31 Aug:
Jamie's proposed design
  TODO

Mai's proposed design
  TODO

        ADVANCED SCHEDULER
        ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

         SURVEY QUESTIONS
         ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?

