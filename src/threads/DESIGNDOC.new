     +--------------------+
     |        CS 5204     |
     | PROJECT 1: THREADS |
     |   DESIGN DOCUMENT  |
     +--------------------+
          
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Jamie Davis <davisjam@vt.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

I consulted "the Internet" (stackoverflow, RMS's gdb guide, etc.) 
to learn how to use cscope and gdb.

Related to the actual content of my code, I did not consult 
any sources other than those named above.

While answering the linux questions, I referred to the following
high-level descriptions.

Are the design documents elsewhere in the linux kernel,
or are they in RFCs or something somewhere?

L1:
  http://www.ibm.com/developerworks/library/l-timers-list/
L2:
  http://www.linuxjournal.com/magazine/real-time-linux-kernel-scheduler?

          ALARM CLOCK
          ===========

---- DATA STRUCTURES ----

>> A1. Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

lib/kernel/priority_queue.h:

/* A priority_queue is an abstract data type consisting of an array of lists,
optionally sorted. */

  struct priority_queue_elem
    {
      struct list_elem elem; /* List element. */
      priority *p;           /* Priority of the element. */
      int64_t *sort_val;     /* Sort by this value if desired. */
    };

#define PRI_QUEUE_NLISTS (1 + PRI_MAX - PRI_MIN)
  struct priority_queue
    {
      struct list queue[PRI_QUEUE_NLISTS];
      size_t size; /* Total number of elements in all lists. */
      /* Useful for the sleeping_queue. Could be handy in other places.
         In the sleeping list we track the minimum wake_me_at value. */  
      int64_t val; 
    };

thread.h:
  struct thread:
    /* Wake a thread in thread_status THREAD_BLOCKED when 0 < wake_me_at <= current timer tick */
    int64_t wake_me_at; 
    struct priority_queue_elem elem;    /* Priority queue element. */
                                           (used to be a struct list_elem elem)

thread.c
  /* Priority queue of sleeping processes. Each priority list is sorted by wake_me_at, soonest to latest. */
  static struct priority_queue sleeping_queue;

Implementation details: 
devices/timer.c::timer_sleep: 
  threads add themselves to sleeping_queue
devices/timer.c::timer_interrupt: 
  interrupt handler calls wake_sleeping_threads,
  which checks if the soonest-to-wake waiter in each list should be woken.
  sleeping_queue.val tracks minimum wake_me_at value across the entire list,
  which lets us quickly decide whether or not to scan the 64 lists in the priority queue.
  By starting at the high-priority end of the queue, we wake a higher-priority thread
  first.

---- COMPARISON TO LINUX ----

>> L1. What data structure does Linux's 4.2 use to implement 
>> its timer facility?  See https://github.com/torvalds/linux/blob/master/kernel/time/timer.c

Via schedule_timeout -> __mod_timer -> internal_add_timer,
sleeping threads are added to a list of sleepers, binned
so that "soon" threads are in the first bin, and later threads
are in subsequent bins covering (increasingly large?) ranges.

The function __next_timer_interrupt is used to identify the 
next-soonest timer that will go off.

When a sleeper's time to wake up occurs, a timer interrupt
is triggered (?) and moves the thread back into a ready state.
It looks like this can also be done via __run_timers?

The function cascade re-locates each timer in the appropriate
bin of a 'struct tvec_base'.

Comparison:
  Bucketing by wakeup time allows linux to add new timers more quickly
than my solution, which has to traverse an entire list (the priority list
in the PQ) looking for the right place to go.
Buckets reduce the potential traversal length.
  When waking threads, the two solutions are comparable, since both maintain 
sorted lists.

      PRIORITY SCHEDULING
      ===================

---- DATA STRUCTURES ----

>> B1. Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

thread.h:
  struct thread:
      priority base_priority;             /* Base priority. */
      priority effective_priority;        /* Effective priority. */
      struct priority_queue_elem elem;    /* Priority queue element. */
      /* Tracks locks held by this thread. 
         Allows us to determine the appropriate (potentially lower) priority level to set
         after releasing a lock, for "priority return." */
      struct list lock_list; 
      /* Tracks the lock for which this thread is waiting, enabling
         nested priority donation. */
      struct lock *pending_lock; /* Lock we want. */

synch.c:
  struct semaphore_elem:
    /* This new field allows us to identify the "largest" element
    in a list of semaphore_elem's. It allows priority wakeup for
    condition variables. It is set to &thr->effective_priority. */

    int64_t *sort_val;                   /* Value on which to sort. */

priority_queue.h, priority_queue.c:
  These files define the interface to and implementation of data structure 'struct priority_queue',
  described above in the alarm clock section.

  /* Mask what a priority is. */
  typedef int64_t priority;

thread.c:
  The ready_list declaration was changed to: 
    static struct priority_queue ready_queue;

Implementation details:
  We maintain sleeping_queue and ready_queue as 64-way priority lists,
  with equal-priority threads scheduled in FIFO fashion.
  Any changes to the priority of a thread in 
  either the ready queue or the sleeping queue requires changing the priority list 
  in which the thread resides.

  In synch.h, the waiters lists of condition variables remain unsorted lists.
  The list elements (priority_queue_elem or semaphore_elem) both have
  a sort_val which is set to the address of the effective priority
  of the relevant thread, allowing us to determine the
  highest priority waiter just-in-time as long as the effective_priority
  of the affected thread(s) is set properly.

---- COMPARISON TO LINUX ----

>> L2. Compare your ready queue design to Linux's design for how it maintains
>> its "real-time" tasks.
>> Look at pick_next_rt_entity in https://github.com/torvalds/linux/blob/master/kernel/sched/rt.c
>> How does your design differ?

In my design, there is a "queue" consisting of 64 lists, one for each possible priority level.
I do not differentiate between "real-time" tasks and "normal" tasks.

Linux has 140 possible priority levels, with the 40 highest levels only available to kernel
threads. Real time priorities range from 0 to 99.

In pick_next_rt_entity, the highest-priority entry in the 'struct rq' (run-queue?) is selected.
A 'struct rq' includes a 'struct rt_prio_array' which tracks MAX_RT_PRIO (i.e. 100) possible
priority levels.

The design for selection of a task is therefore largely the same:
Linux and my designs both involve an array of lists, one for each priority level.

Some differences:
  Linux offers a wider variety of priority levels.

  Linux uses a bitmap to more quickly locate the highest-priority non-empty list from
  which to extract an element, which allows it to avoid iterating over each list
  checking it. I did not use a bitmap so I have to iterate.

  The Linux design gives some weight to *where* to schedule the process (which CPU).
  There seems to be an rq for each CPU, so that tasks can be pushed to and from each other's CPU
    to fill idle cycles. 
  As Pintos is a uni-processor design I had no need to consider this.

  Linux uses locks to protect its rq information, rather than disabling interrupts
  like I do.

  Linux priorities are "inverted": 0 is highest priority, and 139 is lowest priority.
  In my pintos, larger priority values are stronger, up to PRI_MAX of 63.

With respect to the maintenance of a 'struct rq'...
  enqueue_pushable_task: Whenever a new, higher-priority task is pushed to an rq,
    the rt_rq.highest_prio.next value is updated.
  dequeue_pushable_task: Whenever a task is removed from the rq, the highest_prio.next field
    is updated.
  __enqueue_rt_entity: Add this element to the list of appropriate priority.
    Set the appropriate bit in the rq's bitmap to indicate the presence of a task at
    this priority.
  __dequeue_rt_entity: Delete this element from its rq. If it is the last element
    in the list, clear the appropriate bit in the rq's bitmap.

As far as I can tell, the designs are fundamentally the same,
except that Linux uses a bitmap for performance purposes and has to worry about
multiple CPUs.

       ADVANCED SCHEDULER
       ==================

---- DATA STRUCTURES ----

>> C1. Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

lib/kernel/fpra.c, fpra.h:
  Implementation of fixed-point real arithmetic with 14 fractional bits.

  /* Floating-point number. */
  typedef int32_t fp;
  
  /* fp's are divided into an integral and a fractional portion. 
     We allot 1 bit for sign, POINT bits for fractional, and the rest of the 
     bits (32 - 1 - POINT) to integral. */
  #define POINT 14
  
  enum round_mode {
    ROUND_TO_ZERO,
    ROUND_TO_NEAREST
  };
  
  static int ONE = 1 << POINT;

thread.h:
  struct thread:
    int nice; /* The 'nice' value in the mlfqs. */
    fp recent_cpu; /* The 'recent cpu' value in the mlfqs. */
    bool in_time_slice_list;     /* Whether or not we are in the time_slice_threads list. */
    struct list_elem ts_elem;    /* List element for time_slice_threads list. */

thread.c:
  /* List of threads that have run in the last TIME_SLICE ticks. 
     May contain duplicates. List will never be very large so this is OK. */
  static struct list time_slice_threads;

Implementation notes:
  Each time thread_tick() runs, a thread increments its recent_cpu by 1 and
  adds itself to time_slice_threads if(!thr->in_time_slice_list).

  Every 4 timer_tick()'s, we update the recent_cpu of the threads that have run since
  the last time timer_tick() went off (i.e. those in time_slice_threads).
  We then empty that list.
  Every TIMER_FREQ timer_ticks()'s, we recalculate load_avg and update the recent_cpu of all
  threads.

  Although TIME_SLICE == 4, we can't just update recent_cpu of the currently active thread.
  That thread may not have been the only still-alive thread running in this time slice. Another thread
  might have blocked or called thread_yield(), and the currently active thread have been scheduled in
  its place.

---- COMPARISON TO LINUX ----

>> L3. Compare your ready queue design to Linux's design for how it maintains
>> its ready queue for general purpose tasks.
>> See __enqueue_entity in https://github.com/torvalds/linux/blob/master/kernel/sched/fair.c

TODO

>> L4. How many bits does Linux's fixed-point arithmetic (used to compute loadavg) 
>> use for each fixed-point's fractional part?
>> Read: https://github.com/torvalds/linux/blob/master/include/linux/sched.h

11 bits.

From linux/sched.h:
  #define FSHIFT    11    /* nr of bits of precision */
  #define FIXED_1   (1<<FSHIFT) /* 1.0 as fixed-point */

        SURVEY QUESTIONS
        ================

TODO

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

N/A

>> Any other comments?
